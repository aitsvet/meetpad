<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Transcription App</title>
    <script src="https://telegram.org/js/telegram-web-app.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 20px;
            background: var(--tg-theme-bg-color, #ffffff);
            color: var(--tg-theme-text-color, #000000);
        }
        .container {
            max-width: 400px;
            margin: 0 auto;
        }
        .record-btn {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            background: var(--tg-theme-button-color, #0088cc);
            color: var(--tg-theme-button-text-color, #ffffff);
            font-size: 16px;
            cursor: pointer;
            margin: 20px auto;
            display: block;
            transition: all 0.3s;
        }
        .record-btn:active {
            transform: scale(0.95);
        }
        .record-btn.recording {
            background: #ff4444;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        .status {
            text-align: center;
            margin: 20px 0;
            font-weight: bold;
        }
        .timer {
            text-align: center;
            font-size: 24px;
            margin: 10px 0;
        }
        .transcriptions {
            margin-top: 20px;
            max-height: 300px;
            overflow-y: auto;
            border: 1px solid #ccc;
            padding: 10px;
            border-radius: 5px;
        }
        .transcription-item {
            margin-bottom: 10px;
            padding: 10px;
            background: #f5f5f5;
            border-radius: 5px;
            border-left: 3px solid #0088cc;
        }
        .transcription-time {
            font-size: 12px;
            color: #666;
            margin-bottom: 5px;
        }
        .transcription-text {
            font-size: 14px;
            color: #0066cc;
        }
        .logs {
            margin-top: 20px;
            max-height: 200px;
            overflow-y: auto;
            border: 1px solid #ccc;
            padding: 10px;
            border-radius: 5px;
            background: #f8f8f8;
            font-family: monospace;
            font-size: 12px;
        }
        .log-entry {
            margin-bottom: 5px;
            padding: 2px 0;
        }
        .log-time {
            color: #666;
        }
        .log-info {
            color: #0066cc;
        }
        .log-error {
            color: #cc0000;
        }
        .log-success {
            color: #00cc00;
        }
        .telegram-status {
            text-align: center;
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
            font-size: 14px;
        }
        .telegram-connected {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .telegram-disconnected {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Audio Transcription</h1>
        <div class="telegram-status" id="telegramStatus">
            <span id="telegramStatusText">Connecting to Telegram...</span>
        </div>
        <div class="status" id="status">Ready to record</div>
        <div class="timer" id="timer"></div>
        <button class="record-btn" id="recordBtn">ðŸŽ¤</button>
        <p>Click to start/stop recording. Audio is transcribed in 10-second chunks automatically and sent to your Telegram chat.</p>
        <div class="transcriptions" id="transcriptions"></div>
        <div class="logs" id="logs"></div>
    </div>
    <script>
        let tg = window.Telegram.WebApp;
        tg.ready();
        tg.expand();
        let audioContext;
        let audioProcessor;
        let isRecording = false;
        let recordingStartTime;
        let timerInterval;
        let chunkInterval;
        let stream;
        let audioBuffer = [];
        const recordBtn = document.getElementById('recordBtn');
        const status = document.getElementById('status');
        const timer = document.getElementById('timer');
        const transcriptions = document.getElementById('transcriptions');
        const logs = document.getElementById('logs');
        
        // Update Telegram status
        function updateTelegramStatus(connected) {
            const statusElement = document.getElementById('telegramStatus');
            const statusText = document.getElementById('telegramStatusText');
            if (connected) {
                statusElement.className = 'telegram-status telegram-connected';
                statusText.textContent = 'âœ… Connected to Telegram';
            } else {
                statusElement.className = 'telegram-status telegram-disconnected';
                statusText.textContent = 'âŒ Not connected to Telegram';
            }
        }
        
        // Check Telegram connection
        if (tg.initDataUnsafe && tg.initDataUnsafe.user) {
            updateTelegramStatus(true);
            addLog('success', 'Telegram WebApp initialized successfully');
        } else {
            updateTelegramStatus(false);
            addLog('error', 'Telegram WebApp not properly initialized');
        }
        
        recordBtn.addEventListener('click', toggleRecording);
        
        async function startRecording() {
            try {
                addLog('info', 'Requesting microphone access...');
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                addLog('success', 'Microphone access granted');
                
                // Create audio context and processor
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                
                // Buffer size should be power of 2 (2048, 4096, etc.)
                const bufferSize = 4096;
                audioProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
                
                audioBuffer = [];
                
                audioProcessor.onaudioprocess = (e) => {
                    // Get raw audio data (32-bit floating point)
                    const inputData = e.inputBuffer.getChannelData(0);
                    // Add to buffer
                    audioBuffer.push(new Float32Array(inputData));
                };
                
                source.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                isRecording = true;
                recordingStartTime = Date.now();
                recordBtn.classList.add('recording');
                recordBtn.textContent = 'â¹ï¸';
                status.textContent = 'Recording... Click to stop';
                
                addLog('info', 'Recording started');
                
                // Start timer
                timerInterval = setInterval(updateTimer, 100);
                
                // Send chunks every 10 seconds
                chunkInterval = setInterval(() => {
                    if (isRecording && audioBuffer.length > 0) {
                        sendWavChunk();
                    }
                }, 10000);
                
            } catch (error) {
                console.error('Error starting recording:', error);
                addLog('error', `Error starting recording: ${error.message}`);
                status.textContent = 'Error: Cannot access microphone';
            }
        }
        
        function stopRecording() {
            if (!isRecording) return;
            addLog('info', 'Stopping recording...');
            isRecording = false;
            recordBtn.classList.remove('recording');
            recordBtn.textContent = 'ðŸŽ¤';
            status.textContent = 'Stopping...';
            clearInterval(timerInterval);
            clearInterval(chunkInterval);
            timer.textContent = '';
            
            // Disconnect audio processing
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            // Send final chunk if there's any data
            if (audioBuffer.length > 0) {
                addLog('info', 'Sending final audio chunk...');
                sendWavChunk();
                audioBuffer = [];
            }
            
            // Stop stream
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            addLog('success', 'Recording stopped');
            status.textContent = 'Ready to record';
        }
        
        function updateTimer() {
            if (!isRecording) return;
            const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
            timer.textContent = `${elapsed}s`;
        }
        
        function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }
        
        function floatTo16BitPCM(buffer) {
            const dataview = new DataView(new ArrayBuffer(buffer.length * 2));
            let index = 0;
            for (let i = 0; i < buffer.length; i++) {
                const s = Math.max(-1, Math.min(1, buffer[i]));
                const val = s < 0 ? s * 0x8000 : s * 0x7FFF;
                dataview.setInt16(index, val, true);
                index += 2;
            }
            return dataview;
        }
        
        function writeString(dataview, offset, string) {
            for (let i = 0; i < string.length; i++) {
                dataview.setUint8(offset + i, string.charCodeAt(i));
            }
        }
        
        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const dataview = new DataView(buffer);
            
            // RIFF identifier
            writeString(dataview, 0, 'RIFF');
            // file length
            dataview.setUint32(4, 36 + samples.length * 2, true);
            // RIFF type
            writeString(dataview, 8, 'WAVE');
            // format chunk identifier
            writeString(dataview, 12, 'fmt ');
            // format chunk length
            dataview.setUint32(16, 16, true);
            // sample format (1 is PCM)
            dataview.setUint16(20, 1, true);
            // channel count
            dataview.setUint16(22, 1, true);
            // sample rate
            dataview.setUint32(24, sampleRate, true);
            // byte rate (sample rate * block align)
            dataview.setUint32(28, sampleRate * 4, true);
            // block align (channel count * bytes per sample)
            dataview.setUint16(32, 4, true);
            // bits per sample
            dataview.setUint16(34, 16, true);
            // data chunk identifier
            writeString(dataview, 36, 'data');
            // data chunk length
            dataview.setUint32(40, samples.length * 2, true);
            
            // Write PCM samples
            const pcmData = floatTo16BitPCM(samples);
            for (let i = 0; i < pcmData.byteLength; i++) {
                dataview.setUint8(44 + i, pcmData.getUint8(i));
            }
            
            return new Blob([dataview], { type: 'audio/wav' });
        }
        
        function sendWavChunk() {
            if (audioBuffer.length === 0) return;
            
            // Flatten the buffer
            const flatBuffer = new Float32Array(audioBuffer.reduce((acc, val) => acc + val.length, 0));
            let offset = 0;
            for (const buffer of audioBuffer) {
                flatBuffer.set(buffer, offset);
                offset += buffer.length;
            }
            
            // Reset audio buffer
            audioBuffer = [];
            
            // Create proper WAV with header
            const wavBlob = encodeWAV(flatBuffer, audioContext.sampleRate);
            const chunkSize = wavBlob.size;
            
            addLog('info', `Preparing audio chunk (${chunkSize} bytes)`);
            
            // Convert to base64
            const reader = new FileReader();
            reader.onload = async () => {
                const audioData = reader.result;
                const base64Size = audioData.length;
                const endpoint = window.location.origin + '/transcribe';
                
                addLog('info', `Sending to: ${endpoint}`);
                addLog('info', `Data size: ${base64Size} chars (base64), ${chunkSize} bytes (original)`);
                
                try {
                    // Get user info from Telegram
                    const user = tg.initDataUnsafe?.user;
                    const chatId = user?.id;
                    const userId = user?.id || 'unknown';
                    
                    if (!chatId) {
                        addLog('error', 'Cannot get chat ID from Telegram');
                        return;
                    }
                    
                    addLog('info', `User ID: ${userId}, Chat ID: ${chatId}`);
                    
                    // Send to Flask backend
                    const response = await fetch('/transcribe', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            audio_data: audioData,
                            user_id: userId,
                            chat_id: chatId
                        })
                    });
                    
                    if (response.ok) {
                        const result = await response.json();                        
                        if (result.transcription) {
                            addTranscription(result.transcription);
                        }
                    } else {
                        const errorText = await response.text();
                        addLog('error', `Server error: ${errorText}`);
                        console.error('Failed to send audio chunk');
                    }
                } catch (error) {
                    addLog('error', `Network error: ${error.message}`);
                    console.error('Error sending audio:', error);
                }
            };
            reader.readAsDataURL(wavBlob);
        }
        
        function addTranscription(text) {
            const item = document.createElement('div');
            item.className = 'transcription-item';
            const time = document.createElement('div');
            time.className = 'transcription-time';
            time.textContent = new Date().toLocaleTimeString();
            const transcriptionText = document.createElement('div');
            transcriptionText.className = 'transcription-text';
            transcriptionText.textContent = text;
            item.appendChild(time);
            item.appendChild(transcriptionText);
            transcriptions.appendChild(item);
            // Scroll to bottom
            transcriptions.scrollTop = transcriptions.scrollHeight;
        }
        
        function addLog(level, message) {
            const entry = document.createElement('div');
            entry.className = `log-entry log-${level}`;
            const time = document.createElement('span');
            time.className = 'log-time';
            time.textContent = `[${new Date().toLocaleTimeString()}] `;
            const text = document.createElement('span');
            text.textContent = message;
            entry.appendChild(time);
            entry.appendChild(text);
            logs.appendChild(entry);
            // Scroll to bottom
            logs.scrollTop = logs.scrollHeight;
            // Also log to console
            console.log(`[${level.toUpperCase()}] ${message}`);
        }
    </script>
</body>
</html>